2023-03-27 Monday, 27 March 2023

I kind of wish I was more up to date on the current research on consciousness, intelligence etc. There are way too many confident takes re: AGI flooding the zone right now. 

*Update, Tue 28 March 2023:* this looks like an ok primer: <https://consc.net/papers/facing.html> ([via](https://lobste.rs/s/prvzij/just_update_rules_between_neurons#c_hsls8f))

%

> when techno-optimists talk about ML models, they invariably raise every AI experience to the maximum level of personhood it can support and lower every human experience to the most basic technical concept that can even sort of encapsulate it

-- [@noracodes@tenforward.social](https://mastodon.social/@noracodes@tenforward.social/110093093254359927)

%
2023-03-28 Tuesday, 28 March 2023

ðŸ¦ž there's a discussion on lobste.rs about creating a new "llm" tag to enable filtering of stories about Chat-GPT and friends.[1]

My take: 

> Weâ€™re clearly on the <strike>upswing of a hype cycle</strike>cusp of the Singularity. The best thing to do is to <strike>go down to the pub</strike>block the `ai` tag, have a pint, and wait for the whole thing to blow over.

--- 

[1] tags on lobste.rs work a bit differently than on other sites. On the one hand they (attempt to) define what is on topic for the site. On the other, users can either subscribe to them or *filter* them. I don't have hard numbers but I suspect more people filter than subscribe. 

%

Reading about the Norwegian ammo factory not being able to expand because a TikTok data center is sucking up all the power prompts me to believe that when AI takes over, it won't because it will design weapons to kill us, it will be by denying humans the resources to grow food and get clean water. We will starve in the heat exhaust of raw oil-fuelled data centers producing generated cat videos for automated likes. 

%
